# Backchannel Detection for Voice AI

A real-time ML system to detect back-channel utterances ("mhm", "yeah", "makes sense") in voice conversations with <50ms latency.

## Project Structure

```
│── dataset              # dataset gen strategies
|    ├── prompts         # For synthetic datagen
│    ├── dataset_gen.py  # Combines data from synthetic sources and Switchboard
│    ├── backchannel_dataset_cleaned.csv
│    ├── synthetic_dataset_claude.csv
│    └── synthetic_dataset_gemini.csv
├── fastapi/                   # Production API server
│   ├── app/main.py           # FastAPI endpoints
│   ├── src/models.py         # Baseline & ML model implementations
│   ├── src/weights/          # Trained model files
│   └── dockerfile            # Container config
├── training/train.py         # Model training pipeline
├── requirements.txt          # Dependencies
|── sharedlib/transformer_utils.py  # Utils for fasttext model
└── stress_test               # Script for running locust for a stress test
└── requirements.txt          # Dependencies
└── dataset.dockerfile, fastapi.dockerfile  # Dockerfiles to build env.
```

## Quick Start

### 1. Generate Dataset
The dataset can be generated by running the `dataset_gen.py` script inside a Docker container. This script uses the `convokit` library to process the Switchboard corpus and also combines it with synthetic data.

```bash
# Build the Docker image
docker build -t dataset-generator -f dataset.dockerfile .

# Run the container to generate the dataset
docker run --rm -v "$(pwd)":/app dataset-generator
```
This will create/update the `backchannel_dataset_cleaned.csv` file in the `dataset` directory.

### 2. Train Models
```bash
# Prepare CSV with columns: previous_clean, current_clean, label
# sampling is optional to handle class imbalances
python -m training.train --training-file dataset/backchannel_dataset_cleaned.csv --output-dir ./output --sampling (oversample/undersample)

# Copy trained model to API
cp output/backchannel_model_*.joblib fastapi/src/weights/trained_model.joblib
```
The training process generates output directory where the trained weights live.
It also generates the training report.

### 3. Move the results from `output` directory to fastapi/src/weights
we need 3 files:
- `cp output/tfidf_model_*.joblib fastapi/src/weights/tfidf_model.joblib` -> for tfidf model
- `cp output/fasttext_improved_model_*.joblib fastapi/src/weights/fasttext_model.joblib` -> remaining pipeline for fasttext
- `cp output/cc.en.300.bin fastapi/src/weights/` -> for fasttext

### 3. Run API
Move the weights from output directory to fastapi/src/weights before running fastapi
```bash
# Docker build
docker build -t backchannel-api -f fastapi.dockerfile .

# Run
docker run -p 80:80 backchannel-api
```

## API Usage

## API Usage

**Endpoints:**
- `GET /health` - Health check endpoint to verify that the API and models are operational.
- `POST /baseline` - Keyword lookup model
- `POST /tfidfmodel` - Trained tfidf model
- `POST /fasttextmodel` - Trained FastText model


**Request:**
```json
{
  "agent_text": "We have a meeting at 3pm",
  "partial_transcript": "okay"
}
```

**Response:**
```json
{
  "is_backchannel": true,
  "confidence": 0.85
}
```

## Stress Testing

This project uses [Locust](https://locust.io/) to stress test the API. The Locust test script is located in `stress_test/locustfile.py`.

### Running the Stress Test

1. **Install Locust:**
   ```bash
   pip install locust
   ```

2. **Run Locust:**
   By default, the stress test will target `http://localhost:80`. You can change this by setting the `TARGET_HOST` environment variable.

   Start the Locust web interface from the root directory of the project:
   ```bash
   # Run with default host (http://localhost:80)
   locust -f stress_test/locustfile.py

   # Run with a custom host
   TARGET_HOST=http://your-api-host.com locust -f stress_test/locustfile.py
   ```

3. **Start the test:**
   - Open your browser to `http://localhost:8089`.
   - Enter the number of users to simulate and the spawn rate (e.g., 100 users, 10 users/second).
   - Click "Start swarming" to begin the test.

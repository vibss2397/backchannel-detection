# Backchannel Detection for Voice AI

A real-time ML system to detect back-channel utterances ("mhm", "yeah", "makes sense") in voice conversations with <50ms latency.

## Project Structure

```
│── dataset              # dataset gen strategies
|    ├── prompts         # For synthetic datagen
│    ├── dataset_gen.py  # Combines data from synthetic sources and Switchboard
│    ├── backchannel_dataset_cleaned.csv
│    ├── synthetic_dataset_claude.csv
│    └── synthetic_dataset_gemini.csv
├── fastapi/                   # Production API server
│   ├── app/main.py           # FastAPI endpoints
│   ├── src/models.py         # Baseline & ML model implementations
│   ├── src/weights/          # Trained model files
│   └── dockerfile            # Container config
├── training/train.py         # Model training pipeline
├── requirements.txt          # Dependencies
|── sharedlib/transformer_utils.py  # Utils for fasttext model
└── stress_test               # Script for running locust for a stress test
└── requirements.txt          # Dependencies
└── dataset.dockerfile, fastapi.dockerfile  # Dockerfiles to build env.
```

## Quick Start

### 1. Generate Dataset
The dataset can be generated by running the `dataset_gen.py` script inside a Docker container. This script uses the `convokit` library to process the Switchboard corpus and also combines it with synthetic data.

```bash
# Build the Docker image
docker build -t dataset-generator .

# Run the container to generate the dataset
docker run --rm -v "$(pwd)":/app dataset-generator
```
This will create/update the `backchannel_dataset_cleaned.csv` file in the `dataset` directory.

### 2. Train Models
```bash
# Prepare CSV with columns: previous_clean, current_clean, label
python training/train.py --training-file dataset/backchannel_dataset_cleaned.csv --output-dir ./output

# Copy trained model to API
cp output/backchannel_model_*.joblib fastapi/src/weights/trained_model.joblib
```
The training process generates output directory where the trained weights live.
It also generates the training report.

### 3. Run API
Move the weights from output directory to fastapi/src/weights before running fastapi
```bash
# Docker
cd fastapi && docker build -t backchannel-api . && docker run -p 80:80 backchannel-api
```

## API Usage

**Endpoints:**
- `POST /baseline` - Keyword lookup model
- `POST /tfidfmodel` - Trained tfidf model
- `Post /fasttextmodel` - Trained FastText model


**Request:**
```json
{
  "agent_text": "We have a meeting at 3pm",
  "partial_transcript": "okay"
}
```

**Response:**
```json
{
  "is_backchannel": true,
  "confidence": 0.85
}
```
